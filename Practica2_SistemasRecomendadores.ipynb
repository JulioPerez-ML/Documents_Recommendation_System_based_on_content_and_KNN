{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "699b23d6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Usuario\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Usuario\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib \n",
    "from matplotlib import pyplot as plt\n",
    "import string\n",
    "\n",
    "# Imports\n",
    "import pandas as pd\n",
    "\n",
    "import spacy\n",
    "from spacy.tokenizer import Tokenizer\n",
    "from spacy.lang.es import Spanish\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import pickle\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "# https://www.aurigait.com/blog/recommendation-system-using-knn/\n",
    "# https://www.analyticsvidhya.com/blog/2020/08/recommendation-system-k-nearest-neighbors/\n",
    "# https://www.mygreatlearning.com/blog/nltk-tutorial-with-python/\n",
    "# https://www.datacamp.com/community/tutorials/recommender-systems-python\n",
    "# https://stackabuse.com/python-for-nlp-tokenization-stemming-and-lemmatization-with-spacy-library/\n",
    "# https://es.stackoverflow.com/questions/331602/c%C3%B3mo-lematizar-en-espa%C3%B1ol-una-string-con-nltk\n",
    "# https://medium.com/@jae.finger/building-a-marijuana-strain-recommender-system-bef3f66bb2d3\n",
    "# https://scikit-learn.org/stable/modules/neighbors.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb302591",
   "metadata": {},
   "source": [
    "##### Leemos el documento desde el documento de texto plano. Añadimos una columna que indica el género."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "07fd5aba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Género</th>\n",
       "      <th>Documentos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Salud</td>\n",
       "      <td>Los grupos musculares se ejercitan en función ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Salud</td>\n",
       "      <td>Existen dos tipos de actividades física que se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Salud</td>\n",
       "      <td>Los deportes más practicados a nivel mundial s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cine</td>\n",
       "      <td>Las películas con más Oscars de la historia so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ciencia</td>\n",
       "      <td>El sol es una estrella que irradia calor y ene...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Salud</td>\n",
       "      <td>Practicar deporte es altamente recomendado par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Salud</td>\n",
       "      <td>Se han realizado varios estudios reflejando la...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Género                                         Documentos\n",
       "0    Salud  Los grupos musculares se ejercitan en función ...\n",
       "1    Salud  Existen dos tipos de actividades física que se...\n",
       "2    Salud  Los deportes más practicados a nivel mundial s...\n",
       "3     Cine  Las películas con más Oscars de la historia so...\n",
       "4  Ciencia  El sol es una estrella que irradia calor y ene...\n",
       "5    Salud  Practicar deporte es altamente recomendado par...\n",
       "6    Salud  Se han realizado varios estudios reflejando la..."
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file = open(\"Documentos.txt\", \"r\", encoding='utf8')\n",
    "lines = file.readlines()\n",
    "\n",
    "datos = {'Género':['Salud', 'Salud', 'Salud', 'Cine', 'Ciencia', 'Salud', 'Salud'],\n",
    "        'Documentos':lines}\n",
    "df = pd.DataFrame(data = datos)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f6a8a0",
   "metadata": {},
   "source": [
    "##### Eliminamos el elemento '.\\n' que aparece al final de cada registro. Son los datos de salto de línea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c2851c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Los grupos musculares se ejercitan en función del ejercicio específico que se realice, por ejemplo, si quieres realizar un ejercicio de alta intensidad, optarás por uno anaeróbico y viceversa\n",
      "Existen dos tipos de actividades física que se suelen practicar, los ejercicios aeróbicos y los ejercicios anaeróbicos\n",
      "Los deportes más practicados a nivel mundial son el fútbol y el baloncesto, donde se fomenta el compañerismo y el respeto\n",
      "Las películas con más Oscars de la historia son Titanic, BenHur y El Señor de los Anillos\n",
      "El sol es una estrella que irradia calor y energía por toda la vía lactea. Es parte fundamental del sistema solar\n",
      "Practicar deporte es altamente recomendado para mejorar la salud física y mental, según han publicado varias revistas y organismos\n",
      "Se han realizado varios estudios reflejando la importancia del ejericio como medida para contrarrestar el estrés\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\Anaconda2\\envs\\env_python_3_6\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "df_copy = df.copy()\n",
    "for i,x in enumerate(df_copy['Documentos']):\n",
    "        df_copy['Documentos'][i] = df_copy['Documentos'][i][:-2]\n",
    "        print(df_copy['Documentos'][i])\n",
    "\n",
    "df['Documentos'] = df_copy['Documentos']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341cfd91",
   "metadata": {},
   "source": [
    "###### Creamos una columna nueva añadiendo el género al documento, para añadir mas información para el entrenamiento posterior. Además convertimos a minúsculas todas las palabras del documento.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bb75b5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Genero_+_documento'] = df['Género']+ ' ' + df['Documentos']\n",
    "\n",
    "df['Genero_+_documento'] = df['Genero_+_documento'].apply(lambda x: str.lower(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1902b8",
   "metadata": {},
   "source": [
    "##### Definimos una función que realiza lo siguiente:\n",
    "- Eliminamos los signos de puntiación. \n",
    "- Tokenizamos cada documento.\n",
    "- Nos devuelve una lista de palabras a partir del documento que se le pase\n",
    "\n",
    "Aplicamos esta función a cada documento y creamos una nueva columna para almacenar los documentos tokenizados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7f5dab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['salud', 'los', 'grupos', 'musculares', 'se', 'ejercitan', 'en', 'función', 'del', 'ejercicio', 'específico', 'que', 'se', 'realice', 'por', 'ejemplo', 'si', 'quieres', 'realizar', 'un', 'ejercicio', 'de', 'alta', 'intensidad', 'optarás', 'por', 'uno', 'anaeróbico', 'y', 'viceversa']\n",
      "<class 'list'>\n",
      "['salud', 'existen', 'dos', 'tipos', 'de', 'actividades', 'física', 'que', 'se', 'suelen', 'practicar', 'los', 'ejercicios', 'aeróbicos', 'y', 'los', 'ejercicios', 'anaeróbicos']\n",
      "<class 'list'>\n",
      "['salud', 'los', 'deportes', 'más', 'practicados', 'a', 'nivel', 'mundial', 'son', 'el', 'fútbol', 'y', 'el', 'baloncesto', 'donde', 'se', 'fomenta', 'el', 'compañerismo', 'y', 'el', 'respeto']\n",
      "<class 'list'>\n",
      "['cine', 'las', 'películas', 'con', 'más', 'oscars', 'de', 'la', 'historia', 'son', 'titanic', 'benhur', 'y', 'el', 'señor', 'de', 'los', 'anillos']\n",
      "<class 'list'>\n",
      "['ciencia', 'el', 'sol', 'es', 'una', 'estrella', 'que', 'irradia', 'calor', 'y', 'energía', 'por', 'toda', 'la', 'vía', 'lactea', 'es', 'parte', 'fundamental', 'del', 'sistema', 'solar']\n",
      "<class 'list'>\n",
      "['salud', 'practicar', 'deporte', 'es', 'altamente', 'recomendado', 'para', 'mejorar', 'la', 'salud', 'física', 'y', 'mental', 'según', 'han', 'publicado', 'varias', 'revistas', 'y', 'organismos']\n",
      "<class 'list'>\n",
      "['salud', 'se', 'han', 'realizado', 'varios', 'estudios', 'reflejando', 'la', 'importancia', 'del', 'ejericio', 'como', 'medida', 'para', 'contrarrestar', 'el', 'estrés']\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# https://www.mygreatlearning.com/blog/nltk-tutorial-with-python/\n",
    "# https://datagy.io/python-remove-punctuation-from-string/\n",
    "    \n",
    "### Primero tokenizamos los 4 primeros documentos\n",
    "def tokenize_words(text):\n",
    "    sin_puntuacion = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokenized_text=word_tokenize(sin_puntuacion)\n",
    "    print(tokenized_text)\n",
    "    print(type(tokenized_text))\n",
    "    \n",
    "    return tokenized_text\n",
    "\n",
    "# df_tokenized = df.copy()\n",
    "df['Words_tokenized'] = df['Genero_+_documento'].apply(lambda x: tokenize_words(x))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7a4546",
   "metadata": {},
   "source": [
    "##### Definimos una función que filtra cada documento tokenizado para eliminar las stopwords. Creamos otra variable dentro del dataset para almacenar  la nueva lista sin los stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0174f57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_es = nltk.corpus.stopwords.words('spanish')\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    text = [word for word in text if word not in stopword_es]\n",
    "    return text\n",
    "\n",
    "df['Sin_stopwords'] = df['Words_tokenized'].apply(lambda x: remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d81f0943",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Género</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Documentos</th>\n",
       "      <th>Genero_+_documento</th>\n",
       "      <th>Words_tokenized</th>\n",
       "      <th>Sin_stopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Salud</td>\n",
       "      <td>7</td>\n",
       "      <td>Los grupos musculares se ejercitan en función ...</td>\n",
       "      <td>salud los grupos musculares se ejercitan en fu...</td>\n",
       "      <td>[salud, los, grupos, musculares, se, ejercitan...</td>\n",
       "      <td>[salud, grupos, musculares, ejercitan, función...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Salud</td>\n",
       "      <td>5</td>\n",
       "      <td>Existen dos tipos de actividades física que se...</td>\n",
       "      <td>salud existen dos tipos de actividades física ...</td>\n",
       "      <td>[salud, existen, dos, tipos, de, actividades, ...</td>\n",
       "      <td>[salud, existen, dos, tipos, actividades, físi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Salud</td>\n",
       "      <td>6</td>\n",
       "      <td>Los deportes más practicados a nivel mundial s...</td>\n",
       "      <td>salud los deportes más practicados a nivel mun...</td>\n",
       "      <td>[salud, los, deportes, más, practicados, a, ni...</td>\n",
       "      <td>[salud, deportes, practicados, nivel, mundial,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cine</td>\n",
       "      <td>5</td>\n",
       "      <td>Las películas con más Oscars de la historia so...</td>\n",
       "      <td>cine las películas con más oscars de la histor...</td>\n",
       "      <td>[cine, las, películas, con, más, oscars, de, l...</td>\n",
       "      <td>[cine, películas, oscars, historia, titanic, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ciencia</td>\n",
       "      <td>6</td>\n",
       "      <td>El sol es una estrella que irradia calor y ene...</td>\n",
       "      <td>ciencia el sol es una estrella que irradia cal...</td>\n",
       "      <td>[ciencia, el, sol, es, una, estrella, que, irr...</td>\n",
       "      <td>[ciencia, sol, estrella, irradia, calor, energ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Género  Ratings                                         Documentos  \\\n",
       "0    Salud        7  Los grupos musculares se ejercitan en función ...   \n",
       "1    Salud        5  Existen dos tipos de actividades física que se...   \n",
       "2    Salud        6  Los deportes más practicados a nivel mundial s...   \n",
       "3     Cine        5  Las películas con más Oscars de la historia so...   \n",
       "4  Ciencia        6  El sol es una estrella que irradia calor y ene...   \n",
       "\n",
       "                                  Genero_+_documento  \\\n",
       "0  salud los grupos musculares se ejercitan en fu...   \n",
       "1  salud existen dos tipos de actividades física ...   \n",
       "2  salud los deportes más practicados a nivel mun...   \n",
       "3  cine las películas con más oscars de la histor...   \n",
       "4  ciencia el sol es una estrella que irradia cal...   \n",
       "\n",
       "                                     Words_tokenized  \\\n",
       "0  [salud, los, grupos, musculares, se, ejercitan...   \n",
       "1  [salud, existen, dos, tipos, de, actividades, ...   \n",
       "2  [salud, los, deportes, más, practicados, a, ni...   \n",
       "3  [cine, las, películas, con, más, oscars, de, l...   \n",
       "4  [ciencia, el, sol, es, una, estrella, que, irr...   \n",
       "\n",
       "                                       Sin_stopwords  \n",
       "0  [salud, grupos, musculares, ejercitan, función...  \n",
       "1  [salud, existen, dos, tipos, actividades, físi...  \n",
       "2  [salud, deportes, practicados, nivel, mundial,...  \n",
       "3  [cine, películas, oscars, historia, titanic, b...  \n",
       "4  [ciencia, sol, estrella, irradia, calor, energ...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51895b8b",
   "metadata": {},
   "source": [
    "##### Aplicamos stemmización, es decir, sacamos la raíces de las palabras y las almacenaoms en otra variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83b5acf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spanish_stemmer(x):\n",
    "    spanish_stemmer_ = SnowballStemmer(language = 'spanish')\n",
    "    for i in range(len(x)):\n",
    "#         print(i)\n",
    "        for l in range(len(x[i])):\n",
    "#             print(l)\n",
    "            x[i][l] = spanish_stemmer_.stem(x[i][l])\n",
    "#             print(x[i])\n",
    "    return x\n",
    "    \n",
    "df['words_stemmed'] = spanish_stemmer(df['Sin_stopwords'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eff40b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Género</th>\n",
       "      <th>Ratings</th>\n",
       "      <th>Documentos</th>\n",
       "      <th>Genero_+_documento</th>\n",
       "      <th>Words_tokenized</th>\n",
       "      <th>Sin_stopwords</th>\n",
       "      <th>words_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Salud</td>\n",
       "      <td>7</td>\n",
       "      <td>Los grupos musculares se ejercitan en función ...</td>\n",
       "      <td>salud los grupos musculares se ejercitan en fu...</td>\n",
       "      <td>[salud, los, grupos, musculares, se, ejercitan...</td>\n",
       "      <td>[salud, grup, muscular, ejercit, funcion, ejer...</td>\n",
       "      <td>[salud, grup, muscular, ejercit, funcion, ejer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Salud</td>\n",
       "      <td>5</td>\n",
       "      <td>Existen dos tipos de actividades física que se...</td>\n",
       "      <td>salud existen dos tipos de actividades física ...</td>\n",
       "      <td>[salud, existen, dos, tipos, de, actividades, ...</td>\n",
       "      <td>[salud, exist, dos, tip, activ, fisic, suel, p...</td>\n",
       "      <td>[salud, exist, dos, tip, activ, fisic, suel, p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Salud</td>\n",
       "      <td>6</td>\n",
       "      <td>Los deportes más practicados a nivel mundial s...</td>\n",
       "      <td>salud los deportes más practicados a nivel mun...</td>\n",
       "      <td>[salud, los, deportes, más, practicados, a, ni...</td>\n",
       "      <td>[salud, deport, practic, nivel, mundial, futbo...</td>\n",
       "      <td>[salud, deport, practic, nivel, mundial, futbo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cine</td>\n",
       "      <td>5</td>\n",
       "      <td>Las películas con más Oscars de la historia so...</td>\n",
       "      <td>cine las películas con más oscars de la histor...</td>\n",
       "      <td>[cine, las, películas, con, más, oscars, de, l...</td>\n",
       "      <td>[cin, pelicul, oscars, histori, titanic, benhu...</td>\n",
       "      <td>[cin, pelicul, oscars, histori, titanic, benhu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ciencia</td>\n",
       "      <td>6</td>\n",
       "      <td>El sol es una estrella que irradia calor y ene...</td>\n",
       "      <td>ciencia el sol es una estrella que irradia cal...</td>\n",
       "      <td>[ciencia, el, sol, es, una, estrella, que, irr...</td>\n",
       "      <td>[cienci, sol, estrell, irradi, calor, energ, t...</td>\n",
       "      <td>[cienci, sol, estrell, irradi, calor, energ, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Género  Ratings                                         Documentos  \\\n",
       "0    Salud        7  Los grupos musculares se ejercitan en función ...   \n",
       "1    Salud        5  Existen dos tipos de actividades física que se...   \n",
       "2    Salud        6  Los deportes más practicados a nivel mundial s...   \n",
       "3     Cine        5  Las películas con más Oscars de la historia so...   \n",
       "4  Ciencia        6  El sol es una estrella que irradia calor y ene...   \n",
       "\n",
       "                                  Genero_+_documento  \\\n",
       "0  salud los grupos musculares se ejercitan en fu...   \n",
       "1  salud existen dos tipos de actividades física ...   \n",
       "2  salud los deportes más practicados a nivel mun...   \n",
       "3  cine las películas con más oscars de la histor...   \n",
       "4  ciencia el sol es una estrella que irradia cal...   \n",
       "\n",
       "                                     Words_tokenized  \\\n",
       "0  [salud, los, grupos, musculares, se, ejercitan...   \n",
       "1  [salud, existen, dos, tipos, de, actividades, ...   \n",
       "2  [salud, los, deportes, más, practicados, a, ni...   \n",
       "3  [cine, las, películas, con, más, oscars, de, l...   \n",
       "4  [ciencia, el, sol, es, una, estrella, que, irr...   \n",
       "\n",
       "                                       Sin_stopwords  \\\n",
       "0  [salud, grup, muscular, ejercit, funcion, ejer...   \n",
       "1  [salud, exist, dos, tip, activ, fisic, suel, p...   \n",
       "2  [salud, deport, practic, nivel, mundial, futbo...   \n",
       "3  [cin, pelicul, oscars, histori, titanic, benhu...   \n",
       "4  [cienci, sol, estrell, irradi, calor, energ, t...   \n",
       "\n",
       "                                       words_stemmed  \n",
       "0  [salud, grup, muscular, ejercit, funcion, ejer...  \n",
       "1  [salud, exist, dos, tip, activ, fisic, suel, p...  \n",
       "2  [salud, deport, practic, nivel, mundial, futbo...  \n",
       "3  [cin, pelicul, oscars, histori, titanic, benhu...  \n",
       "4  [cienci, sol, estrell, irradi, calor, energ, t...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcf3296",
   "metadata": {},
   "source": [
    "###### Calculamos los valores de TF, IDF y TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7d6d5dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 68)\t0.23955658657259687\n",
      "  (0, 4)\t0.19885253980650688\n",
      "  (0, 42)\t0.23955658657259687\n",
      "  (0, 33)\t0.23955658657259687\n",
      "  (0, 3)\t0.23955658657259687\n",
      "  (0, 51)\t0.19885253980650688\n",
      "  (0, 49)\t0.23955658657259687\n",
      "  (0, 59)\t0.23955658657259687\n",
      "  (0, 15)\t0.23955658657259687\n",
      "  (0, 50)\t0.23955658657259687\n",
      "  (0, 20)\t0.23955658657259687\n",
      "  (0, 16)\t0.39770507961301377\n",
      "  (0, 27)\t0.23955658657259687\n",
      "  (0, 17)\t0.23955658657259687\n",
      "  (0, 40)\t0.23955658657259687\n",
      "  (0, 30)\t0.23955658657259687\n",
      "  (0, 56)\t0.1292685122561784\n",
      "  (1, 1)\t0.3024908939685984\n",
      "  (1, 47)\t0.21462633135822845\n",
      "  (1, 62)\t0.3024908939685984\n",
      "  (1, 25)\t0.2510934196992658\n",
      "  (1, 0)\t0.3024908939685984\n",
      "  (1, 63)\t0.3024908939685984\n",
      "  (1, 14)\t0.3024908939685984\n",
      "  (1, 24)\t0.3024908939685984\n",
      "  :\t:\n",
      "  (4, 61)\t0.5163977794943222\n",
      "  (4, 9)\t0.2581988897471611\n",
      "  (5, 43)\t0.2919126272373849\n",
      "  (5, 55)\t0.2919126272373849\n",
      "  (5, 66)\t0.24231254985824804\n",
      "  (5, 48)\t0.2919126272373849\n",
      "  (5, 57)\t0.2919126272373849\n",
      "  (5, 38)\t0.2919126272373849\n",
      "  (5, 37)\t0.2919126272373849\n",
      "  (5, 52)\t0.2919126272373849\n",
      "  (5, 2)\t0.2919126272373849\n",
      "  (5, 13)\t0.24231254985824804\n",
      "  (5, 47)\t0.20712073490584457\n",
      "  (5, 25)\t0.24231254985824804\n",
      "  (5, 56)\t0.3150413150534153\n",
      "  (6, 22)\t0.33963209777850123\n",
      "  (6, 12)\t0.33963209777850123\n",
      "  (6, 36)\t0.33963209777850123\n",
      "  (6, 18)\t0.33963209777850123\n",
      "  (6, 32)\t0.33963209777850123\n",
      "  (6, 53)\t0.33963209777850123\n",
      "  (6, 23)\t0.33963209777850123\n",
      "  (6, 66)\t0.2819238085219588\n",
      "  (6, 51)\t0.2819238085219588\n",
      "  (6, 56)\t0.18327083643332373\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#Define a TF-IDF Vectorizer Object. Remove all english stop words such as 'the', 'a'\n",
    "tfidf = TfidfVectorizer(analyzer = 'word',lowercase = True, stop_words = stopword_es)\n",
    "\n",
    "#Construct the required TF-IDF matrix by fitting and transforming the data\n",
    "tfidf_matrix = tfidf.fit_transform(df['words_stemmed'].astype('U'))\n",
    "\n",
    "#Output the shape of tfidf_matrix\n",
    "tfidf_matrix.shape\n",
    "\n",
    "print(tfidf_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2433c76",
   "metadata": {},
   "source": [
    "##### Creamos nuestro dataset con los pesos asignados a cada palabra stemmizada. Este dataset es el que usaremos para entrenar nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b80827b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>activ</th>\n",
       "      <th>aerob</th>\n",
       "      <th>alt</th>\n",
       "      <th>alta</th>\n",
       "      <th>anaerob</th>\n",
       "      <th>anill</th>\n",
       "      <th>baloncest</th>\n",
       "      <th>benhur</th>\n",
       "      <th>calor</th>\n",
       "      <th>cienci</th>\n",
       "      <th>...</th>\n",
       "      <th>si</th>\n",
       "      <th>sistem</th>\n",
       "      <th>sol</th>\n",
       "      <th>suel</th>\n",
       "      <th>tip</th>\n",
       "      <th>titanic</th>\n",
       "      <th>tod</th>\n",
       "      <th>vari</th>\n",
       "      <th>via</th>\n",
       "      <th>vicevers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.239557</td>\n",
       "      <td>0.198853</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.239557</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.239557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.302491</td>\n",
       "      <td>0.302491</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.251093</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.302491</td>\n",
       "      <td>0.302491</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.343327</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.353553</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.258199</td>\n",
       "      <td>0.258199</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.258199</td>\n",
       "      <td>0.516398</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.258199</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.258199</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.291913</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.242313</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.281924</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      activ     aerob       alt      alta   anaerob     anill  baloncest  \\\n",
       "0  0.000000  0.000000  0.000000  0.239557  0.198853  0.000000   0.000000   \n",
       "1  0.302491  0.302491  0.000000  0.000000  0.251093  0.000000   0.000000   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   0.343327   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.000000  0.353553   0.000000   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
       "5  0.000000  0.000000  0.291913  0.000000  0.000000  0.000000   0.000000   \n",
       "6  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   0.000000   \n",
       "\n",
       "     benhur     calor    cienci  ...        si    sistem       sol      suel  \\\n",
       "0  0.000000  0.000000  0.000000  ...  0.239557  0.000000  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.302491   \n",
       "2  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "3  0.353553  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.000000  0.258199  0.258199  ...  0.000000  0.258199  0.516398  0.000000   \n",
       "5  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "6  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "        tip   titanic       tod      vari       via  vicevers  \n",
       "0  0.000000  0.000000  0.000000  0.000000  0.000000  0.239557  \n",
       "1  0.302491  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "3  0.000000  0.353553  0.000000  0.000000  0.000000  0.000000  \n",
       "4  0.000000  0.000000  0.258199  0.000000  0.258199  0.000000  \n",
       "5  0.000000  0.000000  0.000000  0.242313  0.000000  0.000000  \n",
       "6  0.000000  0.000000  0.000000  0.281924  0.000000  0.000000  \n",
       "\n",
       "[7 rows x 69 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# dtm = tf.fit_transform(df[‘Criteria’].values.astype(‘U’))\n",
    "#### para la versión del paquete más actual\n",
    "# dtm = pd.DataFrame(tfidf_matrix.todense(), columns=tfidf.get_feature_names_out()) \n",
    "\n",
    "\n",
    "dtm = pd.DataFrame(tfidf_matrix.todense(), columns=tfidf.get_feature_names())\n",
    "dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c91b059",
   "metadata": {},
   "source": [
    "##### Calculamos la similaridad de cada documento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "76299dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.         0.27075317 0.02394891 0.         0.         0.04072492\n",
      "  0.07975241]\n",
      " [0.27075317 1.         0.08252376 0.         0.         0.15672048\n",
      "  0.02991509]\n",
      " [0.02394891 0.08252376 1.         0.         0.         0.17787783\n",
      "  0.03395364]\n",
      " [0.         0.         0.         1.         0.         0.\n",
      "  0.        ]\n",
      " [0.         0.         0.         0.         1.         0.\n",
      "  0.        ]\n",
      " [0.04072492 0.15672048 0.17787783 0.         0.         1.\n",
      "  0.12605156]\n",
      " [0.07975241 0.02991509 0.03395364 0.         0.         0.12605156\n",
      "  1.        ]]\n"
     ]
    }
   ],
   "source": [
    "# https://goodboychan.github.io/python/datacamp/natural_language_processing/2020/07/17/04-TF-IDF-and-similarity-scores.html\n",
    "\n",
    "# Similarity\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "print(cosine_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "139d15d7",
   "metadata": {},
   "source": [
    "###### Entrenamos el modelo de Vecinos más cercanos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df6a8b8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NearestNeighbors(algorithm='brute', metric='cosine', n_neighbors=1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn = NearestNeighbors(n_neighbors=1, algorithm='brute', metric='cosine')\n",
    "\n",
    "nn.fit(dtm.values) # Le pongo values para que no aparezca el warning de los feature names\n",
    "# https://stackoverflow.com/questions/69326639/sklearn-warning-valid-feature-names-in-version-1-0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe219a3",
   "metadata": {},
   "source": [
    "###### Definimos una función que pide por pantalla un documento a partir del cual queremos que el sistema nos recomiende. \n",
    "Le aplicaremos todos los pasos que hemos hecho anteriormente antes de hacer la predicción. Una vez hechos todos esos procesos, nos devuelve la recomendación, es decir, el documento que estaría más cercano al que nosotros hemos introducido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ca6c3565",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recomendar_documentos():\n",
    "    peticion = input('Indique sobre qué quiere una recomendación: \\n')\n",
    "    \n",
    "    tokenized = word_tokenize(str.lower(peticion))\n",
    "    \n",
    "    no_stop_word = remove_stopwords(tokenized)\n",
    "    \n",
    "    stemmed_words = [SnowballStemmer(language = 'spanish').stem(x) for x in no_stop_word]\n",
    "    \n",
    "    recomendacion = nn.kneighbors(tfidf.transform(stemmed_words).todense())\n",
    "    \n",
    "#     print(recomendacion)\n",
    "    \n",
    "    return df['Documentos'][recomendacion[1][0]]\n",
    "#     return df['Documentos'][recomendacion[1][0]],df['Documentos'][recomendacion[1][1]], df['Documentos'][recomendacion[1][2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d3ab61",
   "metadata": {},
   "source": [
    "##### Ejemplos de documentos que leo para para que el sistema me recomiende sobre los que hay:\n",
    "- Las películas del cine más importantes de la historia\n",
    "- El sol es la estrella más importante de nuestro sistema solar pero es una más en el espacio.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "663e2ae3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indique sobre qué quiere una recomendación: \n",
      "El sol es la estrella más importante de nuestro sistema solar pero es una más en el espacio.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4    El sol es una estrella que irradia calor y ene...\n",
       "Name: Documentos, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recomendar_documentos()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78d75e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
